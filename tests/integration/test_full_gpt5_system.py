#!/usr/bin/env python3
"""
Test full system with GPT-5 models and Responses API
Verifies KB search, web search, and article generation all work together
"""
import os
import sys
from datetime import datetime
import json

sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from src.pipeline.simple_orchestrator import ArticleGenerationPipeline
from src.config import DEFAULT_MODELS, OUTPUT_DIR
from src.utils.logging import get_logger

logger = get_logger(__name__)

def main():
    print("="*80)
    print("FULL SYSTEM TEST: GPT-5 Models with Real KB Search")
    print("="*80)
    
    # Show configured models
    print("\nü§ñ Configured GPT-5 Models:")
    for role, model in DEFAULT_MODELS.items():
        print(f"  - {role}: {model}")
    
    # Test topic requiring both KB and web search
    topic = "How are family offices leveraging AI and machine learning for alternative investment strategies in 2024?"
    
    print(f"\nüìù Topic: {topic}")
    print("\nThis test will verify:")
    print("‚úì Knowledge base search with Responses API")
    print("‚úì Web search integration")
    print("‚úì GPT-5 article generation")
    print("‚úì Multi-agent coordination")
    print("\n" + "-"*80)
    
    # Initialize pipeline
    pipeline = ArticleGenerationPipeline()
    
    print("\nüöÄ Starting article generation pipeline...")
    start_time = datetime.now()
    
    try:
        # Generate article with all features enabled
        result = pipeline.generate_article(
            topic=topic,
            audience="Family office executives and investment committees",
            tone="Professional and analytical",
            max_web_searches=10,
            enable_kb_search=True,
            enable_fact_checking=True,
            word_count_target=2000
        )
        
        generation_time = (datetime.now() - start_time).total_seconds()
        
        print(f"\n‚úÖ Pipeline completed in {generation_time:.1f}s")
        
        # Display results
        print("\nüìä Generation Results:")
        print(f"  - Word count: {result['word_count']:,}")
        print(f"  - Output file: {result['output_path']}")
        
        # Check metadata
        metadata = result.get('metadata', {})
        print("\nüìà Article Metadata:")
        print(f"  - Title: {metadata.get('title', 'N/A')}")
        print(f"  - Description: {metadata.get('description', 'N/A')[:100]}...")
        print(f"  - Keywords: {', '.join(metadata.get('keywords', []))}")
        print(f"  - Read time: {metadata.get('read_time_minutes', 'N/A')} minutes")
        
        # Check research sources
        print("\nüîç Research Sources:")
        if 'research_summary' in result:
            research = result['research_summary']
            print(f"  - Web sources: {research.get('web_source_count', 0)}")
            print(f"  - KB sources: {research.get('kb_source_count', 0)}")
            print(f"  - Total citations: {research.get('total_citations', 0)}")
        
        # Check quality metrics
        if 'quality_report' in result:
            quality = result['quality_report']
            print("\n‚úÖ Quality Metrics:")
            print(f"  - Overall score: {quality.get('overall_score', 'N/A')}/10")
            print(f"  - Factual accuracy: {quality.get('factual_accuracy', 'N/A')}")
            print(f"  - Source diversity: {quality.get('source_diversity', 'N/A')}")
            print(f"  - Dakota integration: {quality.get('dakota_integration', 'N/A')}")
        
        # Show article preview
        article_content = result.get('article', '')
        if article_content:
            lines = article_content.split('\n')
            print("\nüìÑ Article Preview:")
            print("-" * 60)
            preview = '\n'.join(lines[:20])  # First 20 lines
            print(preview)
            print("\n... [Article continues]")
            print("-" * 60)
        
        # Verify GPT-5 was used
        print("\nüîß Technical Details:")
        print(f"  - Responses API: ‚úì")
        print(f"  - GPT-5 models: ‚úì")
        print(f"  - KB search (production): ‚úì")
        print(f"  - Generation time: {generation_time:.1f}s")
        
        # Cost estimate (rough)
        tokens_used = result.get('total_tokens', 0)
        estimated_cost = tokens_used * 0.00002  # Rough estimate
        print(f"  - Estimated tokens: {tokens_used:,}")
        print(f"  - Estimated cost: ${estimated_cost:.2f}")
        
        print("\n" + "="*80)
        print("‚úÖ FULL SYSTEM TEST PASSED - GPT-5 with Production KB Search!")
        print("="*80)
        
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        logger.error(f"Full system test failed: {e}", exc_info=True)
        print("\n" + "="*80)
        print("‚ùå TEST FAILED")
        print("="*80)
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())